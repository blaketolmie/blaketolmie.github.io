<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tianxiang Sun (孙天祥)</title>

  <meta name="author" content="Tianxiang Sun">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/fudan_icon.jpg">

  <script type="text/javascript">

    function display(id) {
      var traget = document.getElementById(id);
      if (traget.style.display == "none") {
        traget.style.display = "";
      } else {
        traget.style.display = "none";
      }
    }  
  </script>
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Tianxiang Sun<img style="max-height:50px;vertical-align: middle;"
                        src="images/chinese_name.png" /></name>
                    <!-- <name>Tianxiang Sun <span style="color:black;font-size:22pt;font-family:STFangSong"><b>(孙天祥)</b></span><br/></name> -->
                  </p>
                  <p>I am a 5th-year Ph.D. student at the <a href="https://nlp.fudan.edu.cn/">NLP Lab</a> at <a
                      href="https://www.fudan.edu.cn/en/">Fudan University</a>, advised by Prof. <a
                      href="https://xpqiu.github.io/">Xipeng Qiu</a> and Prof. <a
                      href="https://nlp.fudan.edu.cn/28702/list.htm">Xuanjing Huang</a>. I am also interning at <a
                      href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a>. Previously, I had an internship at <a
                      href="https://damo.alibaba.com/">Alibaba DAMO Academy</a> and <a
                      href="https://www.amazonaws.cn/en/ailab/">Amazon Shanghai AI Lab</a>.
                  </p>
                  <p>
                    My research interests lie in the field of Machine Learning and Natural Language Processing,
                    particularly in pre-trained language models and their optimization-, inference-, and data-efficient
                    methods. Reach out to me over email: <a href="mailto:txsun19@fudan.edu.cn">txsun19@fudan.edu.cn</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="data/Tianxiang-CV.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=puHFkM0AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/txsun1997">Github</a> &nbsp/&nbsp
                    <a href="https://twitter.com/TianxiangSun">Twitter</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/SUN-Tianxiang">Zhihu</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/txsun.jpeg"><img style="width:80%;max-width:80" alt="profile photo"
                      src="images/txsun.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                    <li> <b>[May 2023]</b> Four papers accepted to ACL 2023!</li>
                    <li> <b>[Feb. 2023]</b> We are excited to release <a
                        href="https://txsun1997.github.io/blogs/moss.html">MOSS</a>, a conversational language model.
                      Try it now
                      at <a href="https://moss.fastnlp.top/">moss.fastnlp.top</a>.</li>
                    <li> <b>[Oct. 2022]</b> Three papers accepted to EMNLP 2022!</li>
                    <li> <b>[Aug. 2022]</b> I gave a talk on LMaaS and black-box tuning at <a
                        href="http://www.aitime.cn/">AI Time</a>.</li>
                    <li> <b>[Aug. 2022]</b> I am co-organizing a <a
                        href="https://iacc.pazhoulab-huangpu.com/">PLM-tuning competition</a> (total prize of 1 million
                      RMB) with <a href="https://scholar.google.com/citations?hl=en&user=mou-vPwAAAAJ">Zhengfu He</a>.
                      Welcome!</li>
                    <li> <b>[July 2022]</b> I gave a talk on derivative-free optimization for pre-trained language
                      models at <a href='https://mp.weixin.qq.com/s/CMUbjOJtNCOZnv9UmrAYHg'>MLNLP</a>. Slides <a
                        href="https://txsun1997.github.io/slides/bbt_extension.pdf">here</a>.</li>
                    <li> <b>[July 2022]</b> We have released a <a href='https://github.com/txsun1997/LMaaS-Papers'>paper
                        list</a> on Language-Model-as-a-Service (LMaaS). Feel free to submit pull requests!</li>
                    <li> <b>[May 2022]</b> One paper accepted to ICML 2022 (21.9% acceptance rate)! </li>
                    <a onclick="return display('old_news');"> ---- show more ----</a>
                    <div id="old_news" style="display: none;">
                      <li> <b>[Apr. 2022]</b> Our paradigm shift survey is accepted to Machine Intelligence Research as
                        an
                        invited paper. </li>
                      <li> <b>[Apr. 2022]</b> One paper accepted to NAACL 2022! </li>
                      <li> <b>[Feb. 2022]</b> One paper accepted to ACL 2022 (Findings, 31.4% acceptance rate)! </li>
                      <li> <b>[Oct. 2021]</b> I gave a talk on efficient NLP at <a
                          href='https://www.bilibili.com/video/BV1NL4y1q7tT?vd_source=c04e95624eff313d107e25d2561c2484'>BAAI
                          Big Model Meetup</a>. </li>
                      <li> <b>[Oct. 2021]</b> I gave a talk on paradigm shift in NLP at <a
                          href='https://www.bilibili.com/video/BV1tL4y167F2?vd_source=c04e95624eff313d107e25d2561c2484'>BAAI
                          Qinyuan LIVE</a>. </li>
                      <li> <b>[Sep. 2021]</b> We have released a <a
                          href='https://github.com/txsun1997/awesome-early-exiting'>paper list</a> on early exiting.
                        Feel free to submit pull requests!</li>
                      <li> <b>[Sep. 2021]</b> I gave a talk on CoLAKE at <a
                          href='https://bbs.sffai.com/d/276-colake'>SFFAI</a>. </li>
                      <li> <b>[May 2021]</b> One paper accepted to ACL 2021 (21.2% acceptance rate)!</li>
                      <li> <b>[Mar. 2021]</b> One paper accepted to NAACL 2021 (26% acceptance rate)!</li>
                      <li> <b>[Dec. 2020]</b> I gave a talk on CoLAKE at <a
                          href='https://www.bilibili.com/video/BV1E54y1x7om?p=2&vd_source=c04e95624eff313d107e25d2561c2484'>CSSNLP</a>.
                      </li>
                      <li> <b>[Sep. 2020]</b> One paper accepted to COLING 2020 (32.9% acceptance rate)! </li>
                      <li> <b>[May 2020]</b> Our PTM survey is accepted to SCIENCE CHINA Technological Sciences as an
                        invited paper. </li>
                      <li> <b>[Nov. 2019]</b> I gave a talk on entity linking at <a
                          href='https://www.amazonaws.cn/en/ailab/'>Amazon Shanghai AI Lab</a>. Slides can be downloaded
                        <a href='https://txsun1997.github.io/slides/entity_linking.pdf'>here</a>.
                      </li>
                      <li> <b>[Nov. 2019]</b> My first paper is accepted to AAAI 2020 for oral presentation (4.5% oral
                        presentation acceptance rate)!</li>
                      <li> <b>[Oct. 2019]</b> I joined Amazon Shanghai AI Lab as a research intern, supervised by <a
                          href="https://shanghai.nyu.edu/academics/faculty/directory/zheng-zhang">Zheng Zhang</a>.</li>
                      <li> <b>[Sep. 2019]</b> I joined the NLP Lab at Fudan University as a Ph.D. student.</li>
                      <li> <b>[Jun. 2019]</b> I received B.Eng. from School of Computer Science and Technology at Xidian
                        University. GPA: 3.8/4.0 (top 0.5%)</li>
                    </div>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Publications (</heading><a href="https://txsun1997.github.io/papers">
                    <heading>All Papers</heading>
                  </a>
                  <heading>)</heading>
                  <p>
                    <a href="https://scholar.google.com/citations?user=puHFkM0AAAAJ&hl=en">Google Scholar</a> /
                    <a href="https://www.semanticscholar.org/author/Tianxiang-Sun/153345698">Semantic Scholar</a> / <a
                      href="https://dblp.org/pid/254/1189.html">DBLP</a> / <a
                      href="https://orcid.org/my-orcid?orcid=0000-0001-8291-820X">ORCID</a>
                  </p>
                  <p>
                    (*: Equal contribution)
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/BBTICML2022.png' width="190">
                    </div>
                    <img src='images/BBTICML2022.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://proceedings.mlr.press/v162/sun22e.html">
                    <papertitle>Black-Box Tuning for Language-Model-as-a-Service</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu
                  <br>
                  <em>ICML</em>, 2022 &nbsp <font color="red"><strong>(Spotlight)</strong></font>
                  <br>
                  <a href="https://proceedings.mlr.press/v162/sun22e/sun22e.pdf">pdf</a>
                  /
                  <a href="https://github.com/txsun1997/Black-Box-Tuning">code</a>
                  /
                  <a href="https://txsun1997.github.io/slides/bbt.pdf">slides</a>
                  <p></p>
                  <p>
                    We propose a promising and practical scenario, Language-Model-as-a-Service (LMaaS), where users
                    cannot access model parameters and gradients but can only access language models' output
                    probability. For such a scenario, we propose the black-box tuning to optimize continuous prompts via
                    derivative-free optimization.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ParadigmShift.png' width="190">
                    </div>
                    <img src='images/ParadigmShift.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://link.springer.com/article/10.1007/s11633-022-1331-6">
                    <papertitle>Paradigm Shift in Natural Language Processing</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>, Xiangyang Liu, Xipeng Qiu, Xuanjing Huang
                  <br>
                  <em>Machine Intelligence Research</em>, 2022 &nbsp <font color="red"><strong>(Invited Paper)</strong>
                  </font>
                  <br>
                  <a href="https://link.springer.com/content/pdf/10.1007/s11633-022-1331-6.pdf">pdf</a>
                  /
                  <a href="https://txsun1997.github.io/nlp-paradigm-shift/">project</a>
                  /
                  <a href="https://txsun1997.github.io/slides/nlp-paradigm-shift.pdf">slides</a>
                  <p></p>
                  <p>
                    Recent years have witnessed a trend of paradigm shift in a variety of NLP tasks, which is to solve a
                    task that is originally performed with a paradigm (e.g., sequence labeling) with another paradigm
                    (e.g., machine reading comprehension).
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ElasticBERT.gif' width="190">
                    </div>
                    <img src='images/ElasticBERT.gif' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://aclanthology.org/2022.naacl-main.240/">
                    <papertitle>Towards Efficient NLP: A Standard Evaluation and A Strong Baseline</papertitle>
                  </a>
                  <br>
                  Xiangyang Liu*, <strong>Tianxiang Sun</strong>*, Junliang He, Jiawen Wu, Lingling Wu, Xinyu Zhang, Hao
                  Jiang, Zhao Cao, Xuanjing Huang, Xipeng Qiu
                  <br>
                  <em>NAACL</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://aclanthology.org/2022.naacl-main.240.pdf">pdf</a>
                  /
                  <a href="https://github.com/fastnlp/ElasticBERT">code</a>
                  /
                  <a href="http://eluebenchmark.fastnlp.top/">benchmark</a>
                  /
                  <a href="https://txsun1997.github.io/slides/ELUE.pdf">slides</a>
                  <p></p>
                  <p>
                    We propose a benchmark, ELUE (Efficient Language Understanding Evaluation), for efficient NLP models
                    and a strong baseline/backbone pre-trained model, ElasticBERT.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/CoLAKE.png' width="190">
                    </div>
                    <img src='images/CoLAKE.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://aclanthology.org/2020.coling-main.327/">
                    <papertitle>CoLAKE: Contextualized Language and Knowledge Embedding</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>, Yunfan Shao, Xipeng Qiu, Qipeng Guo, Yaru Hu, Xuanjing Huang, Zheng
                  Zhang
                  <br>
                  <em>COLING</em>, 2020
                  <br>
                  <a href="https://aclanthology.org/2020.coling-main.327.pdf">pdf</a>
                  /
                  <a href="https://github.com/txsun1997/CoLAKE">code</a>
                  /
                  <a href="https://txsun1997.github.io/slides/CoLAKE.pdf">slides</a>
                  <p></p>
                  <p>
                    We pre-train a model called CoLAKE for jointly learning language and knowledge representation by
                    unifying language and knowledge into word-knowledge graphs.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/SesameStreet.jpg' width="190">
                    </div>
                    <img src='images/SesameStreet.jpg' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://link.springer.com/article/10.1007/s11431-020-1647-3">
                    <papertitle>Pre-trained Models for Natural Language Processing: A Survey</papertitle>
                  </a>
                  <br>
                  Xipeng Qiu, <strong>Tianxiang Sun</strong>, Yige Xu, Yunfan Shao, Ning Dai, Xuanjing Huang
                  <br>
                  <em>SCIENCE CHINA Technological Sciences</em>, 2020 &nbsp <font color="red"><strong>(Invited Paper,
                      Most Influential Paper of SCTS in 2020)</strong></font>
                  <br>
                  <a href="https://link.springer.com/content/pdf/10.1007/s11431-020-1647-3.pdf">pdf</a>
                  <p></p>
                  <p>
                    We provide a comprehensive survey of pre-trained models (PTMs) for NLP, ranging from non-contextual
                    word embeddings to state-of-the-art language models. This is a hands-on guide for understanding,
                    using, and developing PTMs for various NLP tasks.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/SparseSharing.png' width="190">
                    </div>
                    <img src='images/SparseSharing.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://ojs.aaai.org//index.php/AAAI/article/view/6424">
                    <papertitle>Learning Sparse Sharing Architectures for Multiple Tasks</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>*, Yunfan Shao*, Xiaonan Li, Pengfei Liu, Hang Yan, Xipeng Qiu, Xuanjing
                  Huang
                  <br>
                  <em>AAAI</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://txsun1997.github.io/papers/aaai2020.pdf">pdf</a>
                  /
                  <a href="https://github.com/choosewhatulike/sparse-sharing">code</a>
                  /
                  <a href="https://txsun1997.github.io/slides/sparse_sharing.pdf">slides</a>
                  <p></p>
                  <p>
                    We propose a new parameter sharing mechanism for multi-task learning, sparse sharing, which
                    allocates a subnet for a task based on lottery ticket hypothesis. The sparse sharing successfully
                    avoids negative transfer between tasks.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Projects & Resources</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/moss.png' width="190">
                    </div>
                    <img src='images/moss.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="http://moss.fastnlp.top/">
                    <papertitle>MOSS: A Conversational Language Model</papertitle>
                  </a>
                  <br>
                  project led by <strong>Tianxiang Sun</strong>
                  <p>
                    MOSS is a conversational language model like ChatGPT. It is capable of following users' instructions
                    to perform various natural language tasks including question answering, generating text, summarzing
                    text, generating code, etc. MOSS is also able to challenge incorrect premises, and reject
                    inappropriate requests. Here is a brief <a
                      href="https://txsun1997.github.io/blogs/moss.html">introduction</a> to MOSS.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/LMaaS.png' width="190">
                    </div>
                    <img src='images/LMaaS.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://github.com/txsun1997/LMaaS-Papers">
                    <papertitle>Paper List on Language-Model-as-a-Service (LMaaS)</papertitle>
                  </a>
                  <br>
                  maintained by <strong>Tianxiang Sun</strong>
                  <p>
                    Pre-trained large language models (LLMs) such as GPT-3 are usually released as a service instead of
                    open sourcing model weights. We call this scenario "Language-Model-as-a-Service (LMaaS)", where
                    users can access the powerful LLMs through their inference APIs. We maintain a curated list of
                    papers that fit into this scenario.
                  </p>
                </td>
              </tr>

              <!-- <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ELUE.png' width="190">
                    </div>
                    <img src='images/ELUE.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="http://eluebenchmark.fastnlp.top/">
                    <papertitle>ELUE: A Multi-dimensional Benchmark for Efficient NLP Methods</papertitle>
                  </a>
                  <br>
                  maintained by <strong>Tianxiang Sun</strong> and <a
                    href="https://scholar.google.com/citations?hl=en&user=U8QD9mwAAAAJ">Xiangyang Liu</a>
                  <p>
                    ELUE (Efficient Language Understanding Evaluation) is a standard benchmark for evaluating and
                    comparing performance, FLOPs, and number of parameters of efficient NLP models such as compressed
                    models and early exiting models.
                  </p>
                </td>
              </tr> -->

              <!-- <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ParadigmShiftPj.png' width="190">
                    </div>
                    <img src='images/ParadigmShiftPj.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://txsun1997.github.io/nlp-paradigm-shift/">
                    <papertitle>Paradigm Shift in Natural Language Processing</papertitle>
                  </a>
                  <br>
                  maintained by <strong>Tianxiang Sun</strong>
                  <p>
                    A paradigm is a general modeling framework or a distinct set of methodologies to solve a class of
                    tasks. For example, sequence labeling is a mainstream paradigm for named entity recognition (NER).
                    Recent years have witnessed a rising trend of paradigm shift, which is solving a task in a new
                    paradigm by reformulating the task.
                  </p>
                </td>
              </tr> -->

            </tbody>
          </table>

          <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Awards</heading>
                <ul>
                  <li> WAIC Yunfan Award (Rising Star, 2023)</li>
                  <li> Academic Star (associated with Fudan University, 10 winners across all the STEM graduate schools, 2023)</li>
                  <li> Most Influential Paper Award of Sci. China Tech Sci. (2022) </li>
                  <li> National Scholarships (Ministry of Education, China, 2020)</li>
                  <li> Outstanding Graduate (associated with Xidian University, 2019)</li>
                  <li> First Prize in China High School Biology Olympiad (2014)</li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Service</heading>
                  <p>
                    <b>Student Seminar Co-Chair</b>
                  </p>
                  <ul>
                    <li> CCL 2023</li>
                  </ul>
                  <p>
                    <b>Reviewer / Program Committee Member</b>
                  </p>
                  <ul>
                    <li> ACL (2021, 2022, 2023)</li>
                    <li> EMNLP (2021, 2022, 2023)</li>
                    <li> COLING (2020, 2022)</li>
                    <li> ICML (2022)</li>
                    <li> NeurIPS (2022, 2023)</li>
                    <li> AAAI (2021)</li>
                    <li> IJCAI (2021)</li>
                  </ul>
                  <em>Will not submit to or write reviews for AAAI/IJCAI since 2022 :)</em>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <script type='text/javascript' id='clustrmaps'
                    src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=aBj-4SCzZBu24IVENbl19cAetpLjEP1RCaSORs6c7A8'></script>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's
                    website</a>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>